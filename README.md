# Software_defect_detection

The complexity and velocity of modern software development have amplified the demand for automated, scalable defect detection. Three main modeling paradigms are covered: supervised learning, unsupervised learning, and transformer-based large language models (LLMs) like CodeBERT and StarCoder2. Using benchmarking datasets such as NASA's Metrics Data Program (MDP) and CodeXGLUE, in this code we investigate the model performance, explainability, and trade-offs. Supervised models, especially Random Forest classifiers trained on structured static code metrics, have high accuracy where labeled data is present. Unsupervised models such as Autoencoders and Isolation Forests provide value where there is no ground truth, and LLMs provide semantic comprehension and suggestive reasoning for challenging defect detection tasks. 
